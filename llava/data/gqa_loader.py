"""
æ™ºèƒ½ GQA æ•°æ®åŠ è½½å™¨ï¼ˆå®Œæ•´ç‰ˆæœ¬ï¼‰
æ”¯æŒæœ¬åœ° parquet ä¸ HuggingFace è¿œç¨‹æ•°æ®é›†ã€‚
è‡ªåŠ¨è¯†åˆ« train/val/testdev/challenge/submission ç­‰ç»“æ„ã€‚
"""

import os
import pandas as pd
from io import BytesIO
from typing import List, Dict, Optional
from PIL import Image
from datasets import Dataset, load_dataset, load_from_disk
from torch.utils.data import DataLoader
from concurrent.futures import ThreadPoolExecutor, as_completed



class GQALoader:
    """ç»Ÿä¸€çš„ GQA æ•°æ®åŠ è½½å™¨"""

    def __init__(self, data_source: str, num_workers: int = 4, batch_size: int = 8, use_cache: bool = True):
        self.data_source = data_source.strip()
        self.num_workers = num_workers
        self.batch_size = batch_size
        self.use_cache = use_cache

        self.is_local = os.path.exists(self.data_source)
        if self.is_local:
            self.gqa_root = self.data_source
            print(f"ä½¿ç”¨æœ¬åœ° GQA æ•°æ®é›†è·¯å¾„: {self.gqa_root}")
        else:
            self.dataset_name = self.data_source
            print(f"ä½¿ç”¨è¿œç¨‹ GQA æ•°æ®é›†: {self.dataset_name}")

    # ------------------------------------------------------------------
    def _find_best_match_dir(self, split_base: str, kind: str) -> Optional[str]:
        """
        æ™ºèƒ½åŒ¹é…æ–‡ä»¶å¤¹ï¼š
        æ”¯æŒ challenge / submission / testdev / train / val / test
        ä¼˜å…ˆé¡ºåºï¼šbalanced > all
        """
        assert kind in ["instructions", "images"]
        candidates = [
            f"{split_base}_balanced_{kind}",
            f"{split_base}_all_{kind}",
            f"{split_base}_{kind}",
        ]
        for cand in candidates:
            path = os.path.join(self.gqa_root, cand)
            if os.path.exists(path):
                return path
        return None

    # ------------------------------------------------------------------
    def _parallel_read_parquets(self, file_list, key_name="id") -> Dict[str, dict]:
        """å¹¶è¡Œè¯»å–å¤šä¸ª parquet æ–‡ä»¶"""
        image_dict = {}
        if not file_list:
            return image_dict

        with ThreadPoolExecutor(max_workers=min(self.num_workers * 2, len(file_list))) as ex:
            futures = {ex.submit(pd.read_parquet, f): f for f in file_list}
            for fut in as_completed(futures):
                df = fut.result()
                for _, row in df.iterrows():
                    image_dict[row[key_name]] = row["image"]

        print(f"å¹¶è¡ŒåŠ è½½å®Œæˆï¼Œå…± {len(image_dict)} å¼ å›¾åƒ")
        return image_dict

    # ------------------------------------------------------------------
    def load_dataset(self, split: str = "train_balanced", num_samples: Optional[int] = None) -> Dataset:
        """åŠ è½½æœ¬åœ°æˆ–è¿œç¨‹æ•°æ®"""
        if self.is_local:
            return self._load_local_dataset(split, num_samples)
        else:
            return self._load_remote_dataset(split, num_samples)

    # ------------------------------------------------------------------
    def _load_local_dataset(self, split: str, num_samples: Optional[int], use_cache: bool = True) -> Dataset:
        """åŠ è½½æœ¬åœ° GQA parquet æ•°æ®ï¼ˆArrow ç¼“å­˜ç‰ˆï¼‰"""
        print(f"åŠ è½½æœ¬åœ° GQA split: {split}")

        split_base = split.replace("_balanced", "").replace("_all", "")
        instructions_dir = self._find_best_match_dir(split_base, "instructions")
        images_dir = self._find_best_match_dir(split_base, "images")

        if not instructions_dir or not images_dir:
            raise FileNotFoundError(
                f"æœªæ‰¾åˆ°åŒ¹é…ç›®å½•ï¼Œè¯·æ£€æŸ¥æ•°æ®è·¯å¾„ã€‚\n"
                f"  æ ¹è·¯å¾„: {self.gqa_root}\n"
                f"  split: {split}\n"
                f"  å¯é€‰: train / val / testdev / challenge / submission / test"
            )

        cache_dir = os.path.join(self.gqa_root, ".gqa_cache")
        os.makedirs(cache_dir, exist_ok=True)
        cache_path = os.path.join(cache_dir, f"{split_base}_arrow")

        # è‹¥å­˜åœ¨ Arrow ç¼“å­˜
        if use_cache and os.path.exists(cache_path):
            print(f"ä» Arrow ç¼“å­˜åŠ è½½: {cache_path}")
            dataset = load_from_disk(cache_path)
            if num_samples:
                dataset = dataset.select(range(min(num_samples, len(dataset))))
            print(f"å·²åŠ è½½ {len(dataset)} æ¡æ ·æœ¬ï¼ˆæ¥è‡ªç¼“å­˜ï¼‰")
            return dataset

        # é¦–æ¬¡åŠ è½½ parquet
        print(f"é¦–æ¬¡åŠ è½½ split={split}ï¼Œè¯»å– parquet æ–‡ä»¶...")
        inst_files = [os.path.join(instructions_dir, f) for f in os.listdir(instructions_dir) if f.endswith(".parquet")]
        img_files = [os.path.join(images_dir, f) for f in os.listdir(images_dir) if f.endswith(".parquet")]

        if not inst_files or not img_files:
            raise FileNotFoundError("åœ¨æŒ‡å®šç›®å½•ä¸­æœªæ‰¾åˆ° parquet æ–‡ä»¶")

        instruction_df = pd.read_parquet(inst_files[0])
        print(f"æŒ‡ä»¤æ•°æ®: {len(instruction_df)} æ¡")

        instruction_ds = Dataset.from_pandas(instruction_df)

        if num_samples:
             instruction_df = instruction_df.head(num_samples)

        image_dict = self._parallel_read_parquets(img_files, "id")
        print(f"å›¾åƒæ•°æ®: {len(image_dict)} å¼ ")

        print("é‡Šæ”¾ instruction_df å†…å­˜...")
        del instruction_df

        # samples = []
        # for _, row in instruction_df.iterrows():
        #     if num_samples and len(samples) >= num_samples:
        #         break
        #     img_id = row.get("imageId")
        #     if not img_id or img_id not in image_dict:
        #         continue
        #     samples.append({
        #         "id": row.get("id", ""),
        #         "imageId": img_id,
        #         "question": row.get("question", ""),
        #         "answer": row.get("answer", ""),
        #         "image_data": image_dict[img_id],
        #     })

        # dataset = Dataset.from_list(samples)

        def add_image_data(sample: Dict) -> Dict:
            img_id = sample.get("imageId")
            if img_id and img_id in image_dict:
                sample["image_data"] = image_dict[img_id]
            else:
                # æ ‡è®°ä»¥ä¾¿åç»­è¿‡æ»¤ï¼ˆæˆ–è€…ä½ ä¹Ÿå¯ä»¥åœ¨è¿™é‡Œå°±è¿”å› Noneï¼‰
                sample["image_data"] = None 
            return sample
        print("ä½¿ç”¨ .map() åˆå¹¶å›¾åƒæ•°æ®...")
        # ä½¿ç”¨ map è¿›è¡Œé«˜æ•ˆåˆå¹¶ï¼Œåˆ©ç”¨å¤šæ ¸
        dataset = instruction_ds.map(
            add_image_data,
            # num_proc=max(self.num_workers, 1), # ä½¿ç”¨å¤šè¿›ç¨‹åŠ é€Ÿ map
            num_proc=1, 
            load_from_cache_file=False,
            desc="Merging images into instructions"
        )
        
        # 6. è¿‡æ»¤æ‰é‚£äº›æ²¡æœ‰åŒ¹é…åˆ°å›¾åƒçš„æ ·æœ¬
        print("è¿‡æ»¤æ— æ•ˆæ ·æœ¬...")
        dataset = dataset.filter(lambda x: x["image_data"] is not None)


        # ç¼“å­˜ä¸º Arrow æ ¼å¼
        dataset.save_to_disk(cache_path)
        print(f"å·²ç¼“å­˜ {len(dataset)} æ¡æ ·æœ¬åˆ° {cache_path}ï¼ˆArrow æ ¼å¼ï¼‰")

        print(f"æˆåŠŸåŠ è½½ {len(dataset)} æ¡æ ·æœ¬")
        return dataset


    # ------------------------------------------------------------------
    def _load_remote_dataset(self, split: str, num_samples: Optional[int] = None) -> Dataset:
        """
        åŠ è½½è¿œç¨‹ HuggingFace GQA æ•°æ®é›† (lmms-lab/GQA)
        è‡ªåŠ¨é€‰æ‹© *_balanced_* > *_all_* é…ç½®å¹¶åˆå¹¶ images + instructionsã€‚
        """
        print(f"åŠ è½½è¿œç¨‹ GQA æ•°æ®é›†: {self.dataset_name}, split={split}")

        # 1 æ„é€ æ‰€æœ‰å€™é€‰é…ç½®ï¼ˆä¼˜å…ˆ balancedï¼‰
        split_base = split.replace("_balanced", "").replace("_all", "")
        possible_insts = [
            f"{split_base}_balanced_instructions",
            f"{split_base}_all_instructions",
        ]
        possible_imgs = [
            f"{split_base}_balanced_images",
            f"{split_base}_all_images",
        ]

        # 2 æŸ¥è¯¢ HuggingFace ä»“åº“çš„å¯ç”¨é…ç½®
        from datasets import get_dataset_config_names
        available = get_dataset_config_names(self.dataset_name)
        print(f"å¯ç”¨é…ç½®: {available} ")

        # 3 é€‰ä¸­ç¬¬ä¸€ä¸ªå­˜åœ¨çš„é…ç½®
        inst_cfg = next((cfg for cfg in possible_insts if cfg in available), None)
        img_cfg  = next((cfg for cfg in possible_imgs  if cfg in available), None)

        if not inst_cfg or not img_cfg:
            raise ValueError(f"åœ¨ {self.dataset_name} ä¸­æœªæ‰¾åˆ°åŒ¹é…é…ç½®ï¼š{possible_insts + possible_imgs}")

        # 4 åŠ è½½ä¸¤ä¸ªå­é›†
        from datasets import DatasetDict
        print(f"-> ä½¿ç”¨ instructions é…ç½®: {inst_cfg}")
        inst_ds_all = load_dataset(self.dataset_name, inst_cfg)
        inst_ds = next(iter(inst_ds_all.values())) if isinstance(inst_ds_all, DatasetDict) else inst_ds_all
        print(f"inst_ds: {inst_ds}")
        print(f"-> ä½¿ç”¨ images é…ç½®: {img_cfg}")
        img_ds_all = load_dataset(self.dataset_name, img_cfg)
        img_ds = next(iter(img_ds_all.values())) if isinstance(img_ds_all, DatasetDict) else img_ds_all
        print(f"img_ds: {img_ds}")

        # 5 pandas åˆå¹¶
        inst_df = inst_ds.to_pandas()
        img_df  = img_ds.to_pandas()

        if num_samples:
            inst_df = inst_df.head(num_samples)

        image_dict = dict(zip(img_df["id"], img_df["image"]))

        def add_image_data(sample: Dict) -> Dict:
            img_id = sample.get("imageId")
            sample["image_data"] = image_dict.get(img_id)
            return sample

        instruction_ds = Dataset.from_pandas(inst_df)
        dataset = instruction_ds.map(
            add_image_data,
            num_proc=1,
            load_from_cache_file=False,
            desc="Merging remote images into instructions"
        )

        dataset = dataset.filter(lambda x: x["image_data"] is not None)
        print(f"åˆå¹¶å®Œæˆï¼Œå…± {len(dataset)} æ¡æ ·æœ¬ï¼ˆè¿œç¨‹ï¼‰")
        return dataset



    # ------------------------------------------------------------------
    def process_sample(self, sample: Dict) -> Dict:
        """åŠ è½½å•ä¸ªæ ·æœ¬å›¾åƒ"""
        processed = sample.copy()
        image = None
        try:
            if "image" in sample and isinstance(sample["image"], Image.Image):
                image = sample["image"]
            elif "image_data" in sample:
                data = sample["image_data"]
                if isinstance(data, dict) and "bytes" in data:
                    image = Image.open(BytesIO(data["bytes"])).convert("RGB")
            elif "image_path" in sample and os.path.exists(sample["image_path"]):
                image = Image.open(sample["image_path"]).convert("RGB")
        except Exception as e:
            print(f"å›¾åƒåŠ è½½å¤±è´¥: {e}")
        processed["image"] = image
        return processed

     # ------------------------------------------------------------------
    def _decode_image(self, data):
        """å®‰å…¨åœ°ä» bytes è§£ç å›¾åƒ"""
        try:
            if isinstance(data, dict) and "bytes" in data:
                return Image.open(BytesIO(data["bytes"])).convert("RGB")
        except Exception:
            return None
        return None
    
    def collate_fn(self, batch):
        """å¹¶è¡Œ decode å›¾åƒ"""
        def decode_safe(b):
            try:
                if "image_data" in b and b["image_data"] is not None:
                    b["image"] = self._decode_image(b["image_data"])
                else:
                    b["image"] = None
            except Exception:
                b["image"] = None
            return b

        with ThreadPoolExecutor(max_workers=min(self.num_workers, len(batch))) as ex:
            batch = list(ex.map(decode_safe, batch))
        return batch

    # ------------------------------------------------------------------
    def as_dataloader(self, split: str, num_samples: Optional[int] = None, dataset: Dataset = None):
        if dataset is None:
            dataset = self._load_local_dataset(split, num_samples) if self.is_local else self._load_remote_dataset(split, num_samples)
        dataloader = DataLoader(
            dataset,
            batch_size=self.batch_size,
            num_workers=self.num_workers,
            pin_memory=True,
            persistent_workers=True,
            shuffle=False,
            collate_fn=self.collate_fn,
        )
        print(f"DataLoader å°±ç»ª: batch_size={self.batch_size}, num_workers={self.num_workers}")
        return dataloader


def test_split(split_name: str, num_samples: int = None):
    print("\n" + "=" * 80)
    print(f"ğŸš€ æµ‹è¯•åŠ è½½ split = '{split_name}'")
    print("=" * 80)

    loader = GQALoader("/home/Dataset/Dataset/GQA")
    # loader = GQALoader("lmms-lab/GQA")

    try:
        import time
        begin_time = time.time()
        dataset = loader.load_dataset(split=split_name, num_samples=num_samples)
        print(f"âœ… æˆåŠŸåŠ è½½ {len(dataset)} ä¸ªæ ·æœ¬")
        end_time = time.time()
        print(f"åŠ è½½æ—¶é—´: {end_time - begin_time} ç§’")

        if len(dataset) > 0:
            sample = dataset[0]
            print(f"ğŸ“‹ æ ·æœ¬é”®: {list(sample.keys())}")
            print(f"ğŸ§  é—®é¢˜: {sample.get('question')}")
            print(f"ğŸ¯ ç­”æ¡ˆ: {sample.get('answer')}")
            print(f"ğŸ–¼ï¸ å›¾åƒID: {sample.get('imageId')}")
        else:
            print("âš ï¸ æ•°æ®é›†ä¸ºç©ºï¼Œè¯·æ£€æŸ¥ parquet æ–‡ä»¶å†…å®¹ã€‚")

    except Exception as e:
        print(f"âŒ åŠ è½½ split='{split_name}' å¤±è´¥: {e}")


if __name__ == "__main__":
    # ä¾æ¬¡æµ‹è¯•å„ç§åˆ†å‰²ç±»å‹
    splits_to_test = [
        # "train", 
        # "val", 
        "testdev",
        # "challenge", 
        # "submission",
        # "test", 
        # "train_all", 
        # "val_balanced"
    ]



    for s in splits_to_test:
        test_split(s)